以下のように実装すれば、**IOnet API**＋**Cloudflare Workers**経由で\*\*ストリーミング（逐次出力）\*\*を実現できます。

## 要約

IOnet は OpenAI API 互換で Chat Completions を提供しており、`stream: true` をリクエストに追加すればモデルが逐次的にレスポンスを送信します ([docs.io.net v2][1])。Cloudflare Workers 側は `fetch()` で得られる `response.body` （`ReadableStream`）をそのままクライアントに返すだけで、ストリーミングを維持できます ([Cloudflare Docs][2])。フロントエンドでは `response.body.getReader()` と `TextDecoder` を使って受信したチャンクを順次表示すれば、チャットUIのように「ワード単位で文字が流れる」演出が可能です ([kevinsimper.dk][3])。

---

## 1. IOnet API での `stream` パラメータ

IOnet は「OpenAI API 互換」を謳っており、Chat Completions の全パラメータ（`stream` も含む）をサポートします ([docs.io.net v2][1])。

```jsonc
{
  "model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
  "stream": true,
  "temperature": 0.7,
  "max_completion_tokens": 1024,
  "messages": [
    { "role": "system", "content": "You are a helpful assistant." },
    { "role": "user",   "content": "Explain quantum computing" }
  ]
}
```

---

## 2. Workers 側でのストリーミングプロキシ

Cloudflare Workers は Web 標準の Streams API をサポートしており、`response.body` をそのまま返却することでストリーミングを維持できます ([Cloudflare Docs][2])。以下のように実装します。

```js
export default {
  async fetch(request, env) {
    // プロンプトはクライアントから丸ごと受け取る
    const userInput = await request.json();

    // IOnet に stream=true で問い合わせ
    const apiRes = await fetch("https://api.intelligence.io.solutions/api/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${env.IONET_API_KEY}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify({ ...userInput, stream: true })
    });

    // CORS ヘッダー等を追加してストリーミングをそのまま返却
    return new Response(apiRes.body, {
      status: apiRes.status,
      headers: {
        "Content-Type": "application/json; charset=utf-8",
        "Access-Control-Allow-Origin": "*"
      }
    });
  }
}
```

---

## 3. フロントエンドでの受信＆表示

フロントでは `fetch()` の `.body` を `ReadableStreamDefaultReader` で読み取り、チャンクごとに `TextDecoder` でデコードして表示します ([kevinsimper.dk][3])。

```html
<div id="chat"></div>
<script>
async function streamChat(prompt) {
  const res = await fetch("https://<your-worker>.workers.dev", {
    method: "POST",
    headers: {"Content-Type":"application/json"},
    body: JSON.stringify({
      model: "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      stream: true,
      messages: [
        {role:"system",content:"You are a helpful assistant."},
        {role:"user",content:prompt}
      ]
    })
  });

  const reader = res.body.getReader();
  const decoder = new TextDecoder("utf-8");
  let chatDiv = document.getElementById("chat");
  chatDiv.innerText = "";

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    chatDiv.innerText += decoder.decode(value, { stream: true });
    // optional: scroll to bottom
    chatDiv.scrollTop = chatDiv.scrollHeight;
  }
}

// 使用例
streamChat("Explain quantum computing");
</script>
```

---

### ポイントまとめ

* **IOnet の `stream: true`** で逐次データ取得 ([docs.io.net v2][1])
* **Workers は `apiRes.body` をそのまま返す** だけでストリーミングを維持 ([Cloudflare Docs][2])
* **フロントで `getReader()` ＋ `TextDecoder`** によるチャンク単位表示 ([kevinsimper.dk][3])

この構成で、ユーザーには低レイテンシに「文字が流れる」ようなリアルタイム出力を提供できます。

[1]: https://docs.io.net/reference/get-started-with-io-intelligence-api?utm_source=chatgpt.com "Getting Started with API Models - io.net Docs"
[2]: https://developers.cloudflare.com/workers/runtime-apis/streams/?utm_source=chatgpt.com "Streams - Runtime APIs · Cloudflare Workers docs"
[3]: https://kevinsimper.dk/posts/streaming-an-ai-prompt-with-cloudflare-worker?utm_source=chatgpt.com "Streaming an AI prompt with Cloudflare Worker - Kevin Simper"
