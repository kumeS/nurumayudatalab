/**
 * AI Service - IO Intelligence API Integration
 * Handles communication with IO Intelligence API
 */

class AIService {
    constructor(storageManager) {
        this.storageManager = storageManager;
        this.currentProvider = 'io_intelligence';
        this.requestQueue = [];
        this.isProcessing = false;
        this.rateLimits = {
            io_intelligence: { requests: 0, resetTime: 0, limit: 100 }
        };
    }

    /**
     * Set the preferred AI provider
     * @param {string} provider - 'io_intelligence'
     */
    setProvider(provider) {
        if (provider === 'io_intelligence') {
            this.currentProvider = provider;
        } else {
            throw new Error(`Unsupported provider: ${provider}. Only io_intelligence is supported.`);
        }
    }

    /**
     * Get available API keys
     * @returns {Object} Available API keys
     */
    getAvailableProviders() {
        const available = {};

        if (this.storageManager.hasApiKey('io_intelligence')) {
            available.io_intelligence = 'IO Intelligence';
        }

        return available;
    }

    /**
     * Check if current provider is available
     * @returns {boolean} Provider availability
     */
    isProviderAvailable(provider = this.currentProvider) {
        return provider === 'io_intelligence' && this.storageManager.hasApiKey('io_intelligence');
    }

    /**
     * Improve prompt using AI (Stage 1)
     * @param {string} originalPrompt - Original user prompt
     * @param {string} provider - AI provider to use
     * @returns {Promise<string>} Improved prompt
     */
    async improvePrompt(originalPrompt, provider = this.currentProvider) {
        if (!this.isProviderAvailable(provider)) {
            throw new Error(`Provider ${provider} is not configured`);
        }

        const systemPrompt = `ã‚ãªãŸã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®å°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤ºæ–‡ã‚’åˆ†æã—ã€ã‚ˆã‚Šæ˜ç¢ºã§å…·ä½“çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ”¹è‰¯ã—ã¦ãã ã•ã„ã€‚

æ”¹è‰¯ã®ãƒã‚¤ãƒ³ãƒˆï¼š
1. æ›–æ˜§ãªè¡¨ç¾ã‚’å…·ä½“çš„ã«ã™ã‚‹
2. å¿…è¦ãªæƒ…å ±ã‚„åˆ¶ç´„æ¡ä»¶ã‚’æ˜è¨˜ã™ã‚‹
3. å‡ºåŠ›å½¢å¼ã‚„æœŸå¾…ã™ã‚‹çµæœã‚’æ˜ç¢ºã«ã™ã‚‹
4. æ€è€ƒéç¨‹ã‚’ä¿ƒã™ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ ã™ã‚‹

å…ƒã®æ„å›³ã‚’ä¿ã¡ãªãŒã‚‰ã€AIãŒã‚ˆã‚Šè‰¯ã„å›ç­”ã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ãªæŒ‡ç¤ºæ–‡ã«æ”¹è‰¯ã—ã¦ãã ã•ã„ã€‚`;

        const messages = [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: `æ”¹è‰¯ã—ã¦ãã ã•ã„ï¼š\n${originalPrompt}` }
        ];

        try {
            const response = await this.sendRequest(messages, provider, {
                temperature: 0.3,
                maxTokens: 500
            });

            return response.content;
        } catch (error) {
            console.error('Prompt improvement failed:', error);
            throw new Error(`ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹è‰¯ã«å¤±æ•—ã—ã¾ã—ãŸ: ${error.message}`);
        }
    }

    /**
     * Execute prompt with specific thinking pattern
     * @param {string} prompt - Prompt to execute
     * @param {string} thinkingPattern - Thinking pattern prompt
     * @param {string} patternName - Name of the thinking pattern
     * @param {string} provider - AI provider to use
     * @returns {Promise<Object>} Execution result
     */
    async executeWithPattern(prompt, thinkingPattern, patternName, provider = this.currentProvider) {
        if (!this.isProviderAvailable(provider)) {
            throw new Error(`Provider ${provider} is not configured`);
        }

        const fullPrompt = `${thinkingPattern}\n\nä»¥ä¸‹ã®æŒ‡ç¤ºã«å¯¾ã—ã¦ä¸Šè¨˜ã®æ€è€ƒæ–¹æ³•ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š\n${prompt}`;

        const messages = [
            { role: 'user', content: fullPrompt }
        ];

        try {
            const startTime = Date.now();
            const response = await this.sendRequest(messages, provider, {
                temperature: 0.7,
                maxTokens: 1000
            });

            const endTime = Date.now();

            return {
                content: response.content,
                patternName: patternName,
                provider: provider,
                executionTime: endTime - startTime,
                timestamp: new Date().toISOString(),
                tokenUsage: response.tokenUsage || null
            };
        } catch (error) {
            console.error(`Pattern execution failed for ${patternName}:`, error);
            throw new Error(`${patternName}ã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ: ${error.message}`);
        }
    }

    /**
     * Send request to AI provider
     * @param {Array} messages - Messages array
     * @param {string} provider - AI provider
     * @param {Object} options - Request options
     * @returns {Promise<Object>} API response
     */
    async sendRequest(messages, provider, options = {}) {
        await this.checkRateLimit(provider);
        
        const apiKey = this.storageManager.getApiKey(provider);
        
        if (!apiKey) {
            throw new Error(`API key for ${provider} not found. Please set up your API key in settings or ensure environment variables are configured.`);
        }

        switch (provider) {
            case 'io_intelligence':
                return await this.callIOIntelligence(messages, apiKey, options);
            default:
                throw new Error(`Unsupported provider: ${provider}. Only io_intelligence is supported.`);
        }
    }

    /**
     * Call IO Intelligence API
     * @param {Array} messages - Messages array
     * @param {string} apiKey - API key
     * @param {Object} options - Request options
     * @returns {Promise<Object>} Response
     */
    async callIOIntelligence(messages, apiKey, options) {
        // Resolve endpoint from ENV_CONFIG with safe fallback
        const endpoint = (typeof window !== 'undefined' && window.ENV_CONFIG && window.ENV_CONFIG.API_ENDPOINTS && window.ENV_CONFIG.API_ENDPOINTS.IO_INTELLIGENCE)
            ? window.ENV_CONFIG.API_ENDPOINTS.IO_INTELLIGENCE
            : 'https://api.intelligence.io.solutions/api/v1/chat/completions';

        let response;
        try {
            response = await fetch(endpoint, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${apiKey}`
                },
                body: JSON.stringify({
                    model: options.model || (typeof window !== 'undefined' && window.ENV_CONFIG?.DEFAULT_SETTINGS?.DEFAULT_MODEL) || 'openai/gpt-oss-120b',
                    messages: messages,
                    reasoning_content: (typeof window !== 'undefined' && window.ENV_CONFIG?.DEFAULT_SETTINGS?.REASONING_CONTENT) ?? false,
                    temperature: options.temperature || 0.7,
                    max_tokens: options.maxTokens || 1000
                })
            });
        } catch (networkError) {
            console.error('IOnet API Network/CORS Error:', {
                message: networkError?.message,
                endpoint
            });
            // Typical in browsers when CORS blocks or offline
            throw new Error(`APIã«æ¥ç¶šã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¾ãŸã¯CORSã®å¯èƒ½æ€§ï¼‰ã€‚ãƒ­ãƒ¼ã‚«ãƒ«ã§é–‹ç™ºä¸­ã®å ´åˆã¯ãƒ—ãƒ­ã‚­ã‚·ã‚’èµ·å‹•ã—ã¦ãã ã•ã„: \`node api-proxy-server.js\`ï¼ˆãƒãƒ¼ãƒˆ3001ï¼‰ã€‚ã¾ãŸã¯HTTPã‚µãƒ¼ãƒãƒ¼çµŒç”±ã§å®Ÿè¡Œã—ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯/CORSè¨­å®šã‚’ã”ç¢ºèªãã ã•ã„ã€‚è©³ç´°: ${networkError?.message || 'Unknown error'}`);
        }

        if (!response.ok) {
            const errorText = await response.text().catch(() => '');
            let errorData;
            try {
                errorData = JSON.parse(errorText);
            } catch {
                errorData = { error: { message: errorText || `HTTP ${response.status}` } };
            }
            
            console.error('IOnet API Error:', {
                status: response.status,
                statusText: response.statusText,
                errorData: errorData,
                endpoint,
                apiKeyPrefix: apiKey.substring(0, 10) + '...'
            });
            
            const errorMessage = errorData.error?.message || `IOnet API error: ${response.status} ${response.statusText}`;

            // Add more specific error messages for common issues
            if (response.status === 401) {
                throw new Error('APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚');
            } else if (response.status === 429) {
                throw new Error('APIä½¿ç”¨é‡ã®ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚');
            } else if (response.status === 500) {
                throw new Error('ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚');
            }

            throw new Error(errorMessage);
        }

        const data = await response.json();
        this.updateRateLimit('io_intelligence');

        return {
            content: data.choices?.[0]?.message?.content || '',
            tokenUsage: data.usage
        };
    }




    /**
     * Check rate limit before making request
     * @param {string} provider - AI provider
     */
    async checkRateLimit(provider) {
        const limit = this.rateLimits[provider];
        const now = Date.now();

        // Reset counter if time window has passed (1 minute)
        if (now > limit.resetTime) {
            limit.requests = 0;
            limit.resetTime = now + 60000; // 1 minute from now
        }

        // Check if we've hit the rate limit
        if (limit.requests >= limit.limit) {
            const waitTime = limit.resetTime - now;
            throw new Error(`Rate limit exceeded for ${provider}. Please wait ${Math.ceil(waitTime / 1000)} seconds.`);
        }
    }

    /**
     * Update rate limit counter
     * @param {string} provider - AI provider
     */
    updateRateLimit(provider) {
        this.rateLimits[provider].requests++;
    }

    /**
     * Execute multiple patterns concurrently with queue management
     * @param {string} prompt - Prompt to execute
     * @param {Array} patterns - Array of pattern objects
     * @param {Function} progressCallback - Progress update callback
     * @returns {Promise<Array>} Array of results
     */
    async executeMultiplePatterns(prompt, patterns, progressCallback) {
        const availableProviders = Object.keys(this.getAvailableProviders());
        
        if (availableProviders.length === 0) {
            throw new Error('No AI providers are configured. Please set up API keys in settings.');
        }

        const results = [];
        const errors = [];

        // Process patterns with controlled concurrency to avoid rate limits
        const configuredMax = (typeof window !== 'undefined' && window.ENV_CONFIG?.DEFAULT_SETTINGS?.MAX_CONCURRENCY) || 3;
        const maxConcurrency = Math.min(Number(configuredMax) || 3, patterns.length);
        const chunks = this.chunkArray(patterns, maxConcurrency);

        for (let chunkIndex = 0; chunkIndex < chunks.length; chunkIndex++) {
            const chunk = chunks[chunkIndex];
            const chunkPromises = chunk.map(async (pattern, index) => {
                const provider = availableProviders[index % availableProviders.length];
                
                try {
                    progressCallback(pattern.name, 'running');
                    
                    const result = await this.executeWithPattern(
                        prompt,
                        pattern.prompt,
                        pattern.name,
                        provider
                    );
                    
                    progressCallback(pattern.name, 'completed');
                    return { patternId: pattern.id, success: true, data: result };
                    
                } catch (error) {
                    progressCallback(pattern.name, 'error');
                    return { 
                        patternId: pattern.id, 
                        success: false, 
                        error: error.message,
                        patternName: pattern.name 
                    };
                }
            });

            const chunkResults = await Promise.all(chunkPromises);
            
            chunkResults.forEach(result => {
                if (result.success) {
                    results.push(result);
                } else {
                    errors.push(result);
                }
            });

            // Add delay between chunks to respect rate limits
            if (chunkIndex < chunks.length - 1) {
                await this.delay(1000);
            }
        }

        return { results, errors };
    }

    /**
     * Summarize multiple results into a single coherent analysis
     * @param {Array} results - Array of pattern results
     * @param {string} originalPrompt - Original prompt
     * @returns {Promise<string>} Summary result
     */
    async summarizeResults(results, originalPrompt) {
        if (results.length === 0) {
            throw new Error('No results to summarize');
        }

        const availableProviders = Object.keys(this.getAvailableProviders());
        if (availableProviders.length === 0) {
            throw new Error('No AI providers configured for summarization');
        }

        const resultsText = results.map(result => 
            `ã€${result.data.patternName}ã€‘\n${result.data.content}\n`
        ).join('\n---\n\n');

        const summaryPrompt = `ä»¥ä¸‹ã¯ã€Œ${originalPrompt}ã€ã¨ã„ã†æŒ‡ç¤ºã«å¯¾ã—ã¦ã€è¤‡æ•°ã®æ€è€ƒãƒ‘ã‚¿ãƒ¼ãƒ³ã§åˆ†æã—ãŸçµæœã§ã™ã€‚

${resultsText}

ã“ã‚Œã‚‰ã®åˆ†æçµæœã‚’çµ±åˆã—ã¦ã€ä»¥ä¸‹ã®æ§‹æˆã§åŒ…æ‹¬çš„ãªå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

## ğŸ¯ çµ±åˆåˆ†æçµæœ

### ä¸»è¦ãªå…±é€šç‚¹
- å„æ€è€ƒãƒ‘ã‚¿ãƒ¼ãƒ³ã§å…±é€šã—ã¦æŒ‡æ‘˜ã•ã‚Œã¦ã„ã‚‹é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

### å¤šè§’çš„è¦–ç‚¹ã‹ã‚‰ã®æ´å¯Ÿ
- ç•°ãªã‚‹æ€è€ƒãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸç‹¬è‡ªã®è¦–ç‚¹ã‚„ç™ºè¦‹

### å®Ÿè¡Œå¯èƒ½ãªææ¡ˆ
- åˆ†æçµæœã‚’åŸºã«ã—ãŸå…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³

### æ³¨æ„ã™ã¹ããƒªã‚¹ã‚¯ã¨å¯¾ç­–
- å„åˆ†æã§æŒ‡æ‘˜ã•ã‚ŒãŸãƒªã‚¹ã‚¯ã¨ãã®å¯¾ç­–

### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
- ä»Šå¾Œæ¤œè¨ã™ã¹ãäº‹é …ã‚„è¿½åŠ èª¿æŸ»ãŒå¿…è¦ãªé ˜åŸŸ

è«–ç†çš„ã§å®Ÿç”¨çš„ãªçµ±åˆåˆ†æã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚`;

        try {
            const provider = availableProviders[0]; // Use first available provider
            const messages = [
                { role: 'user', content: summaryPrompt }
            ];

            const response = await this.sendRequest(messages, provider, {
                temperature: 0.5,
                maxTokens: 1500
            });

            return response.content;
        } catch (error) {
            console.error('Summarization failed:', error);
            throw new Error(`çµæœã®çµ±åˆã«å¤±æ•—ã—ã¾ã—ãŸ: ${error.message}`);
        }
    }

    /**
     * Utility function to chunk array
     * @param {Array} array - Array to chunk
     * @param {number} chunkSize - Size of each chunk
     * @returns {Array} Chunked array
     */
    chunkArray(array, chunkSize) {
        const chunks = [];
        for (let i = 0; i < array.length; i += chunkSize) {
            chunks.push(array.slice(i, i + chunkSize));
        }
        return chunks;
    }

    /**
     * Utility delay function
     * @param {number} ms - Milliseconds to delay
     * @returns {Promise} Promise that resolves after delay
     */
    delay(ms) {
        return new Promise(resolve => setTimeout(resolve, ms));
    }

    /**
     * Get cost estimation for request
     * @param {string} provider - AI provider
     * @param {number} inputTokens - Estimated input tokens
     * @param {number} outputTokens - Estimated output tokens
     * @returns {number} Estimated cost in USD
     */
    estimateCost(provider, inputTokens, outputTokens) {
        // IO Intelligence pricing (estimated)
        const pricing = {
            io_intelligence: {
                input: 0.001 / 1000,   // Estimated per 1k tokens
                output: 0.001 / 1000
            }
        };

        const rates = pricing[provider];
        if (!rates) return 0;

        return (inputTokens * rates.input) + (outputTokens * rates.output);
    }
}

// Export for use in other modules
if (typeof module !== 'undefined' && module.exports) {
    module.exports = AIService;
} else {
    window.AIService = AIService;
}
